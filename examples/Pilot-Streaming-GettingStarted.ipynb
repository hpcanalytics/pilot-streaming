{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Pilot-Streaming on Wrangler\n",
    "\n",
    "In the first step we need to import all required packages and modules into the Python Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T17:59:21.386383Z",
     "start_time": "2017-12-28T17:59:21.364643Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/01131/tg804093/anaconda2/lib/python2.7/site-packages/radical/utils/atfork/stdlib_fixer.py:72: UserWarning: logging handlers already registered.\n",
      "  warnings.warn('logging handlers already registered.')\n"
     ]
    }
   ],
   "source": [
    "# System Libraries\n",
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "\n",
    "## logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "logging.getLogger(\"py4j\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "# Pilot-Streaming\n",
    "import pilot.streaming\n",
    "sys.modules['pilot.streaming']\n",
    "\n",
    "### Required Spark configuration that needs to be provided before pyspark is imported and JVM started\n",
    "os.environ[\"SPARK_LOCAL_IP\"]='129.114.58.2' #must be done before pyspark is loaded\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pilot-Compute Description is a simple key/value style description of the cluster environment that should be started. Alternatively, the commandline tool delivered with this package can be used:\n",
    "\n",
    "     pilot-streaming --resource=slurm://localhost --queue=normal --walltime=59 --number_cores=48 --framework spark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:00:04.950564Z",
     "start_time": "2017-12-28T17:59:22.095228Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Job: 59214 State : Pending\n",
      "Create Spark Context for URL: spark://129.114.58.133:7077\n"
     ]
    }
   ],
   "source": [
    "pilot_compute_description = {\n",
    "    \"resource\":\"slurm://localhost\",\n",
    "    \"working_directory\": os.path.join('/work/01131/tg804093/wrangler/', \"work\"),\n",
    "    \"number_cores\": 48,\n",
    "    \"cores_per_node\":1,\n",
    "    \"project\": \"TG-MCB090174\",\n",
    "    \"queue\": \"normal\",\n",
    "    \"walltime\": 59,\n",
    "    \"type\":\"spark\"\n",
    "}\n",
    "spark_pilot = pilot.streaming.PilotComputeService.create_pilot(pilot_compute_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'master_url': 'spark://129.114.58.133:7077',\n",
       " 'spark_home': '/work/01131/tg804093/wrangler/work/spark-7ffff27c-f028-11e7-b547-549f35083c1c/spark-2.2.1-bin-hadoop2.7',\n",
       " 'web_ui_url': 'http://129.114.58.133:8080'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_pilot.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T17:51:55.430862Z",
     "start_time": "2017-12-28T17:51:55.093479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Spark Context for URL: spark://129.114.58.133:7077\n"
     ]
    }
   ],
   "source": [
    "sc = spark_pilot.get_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1,2,3])\n",
    "rdd.map(lambda a: a*a).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_pilot.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Job: 59230 State : Pending\n",
      "look for configs in: /work/01131/tg804093/wrangler/work/kafka-61bbf196-f030-11e7-905c-549f35083c1c/config\n",
      "['broker-0']\n",
      "Kafka Config: /work/01131/tg804093/wrangler/work/kafka-61bbf196-f030-11e7-905c-549f35083c1c/config (Tue Jan  2 20:48:20 2018)\n",
      "{'zookeeper.connection.timeout.ms': '6000', 'broker.id': '0', 'listeners': 'PLAINTEXT://c251-132:9092', 'zookeeper.connect': 'c251-132:2181'}\n"
     ]
    }
   ],
   "source": [
    "pilot_compute_description = {\n",
    "    \"resource\":\"slurm://localhost\",\n",
    "    \"working_directory\": os.path.join('/work/01131/tg804093/wrangler/', \"work\"),\n",
    "    \"number_cores\": 48,\n",
    "    \"cores_per_node\":1,\n",
    "    \"project\": \"TG-MCB090174\",\n",
    "    \"queue\": \"normal\",\n",
    "    \"walltime\": 59,\n",
    "    \"type\":\"kafka\"\n",
    "}\n",
    "kafka_pilot = pilot.streaming.PilotComputeService.create_pilot(pilot_compute_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'details': {'broker.id': '0',\n",
       "  'listeners': 'PLAINTEXT://c251-132:9092',\n",
       "  'zookeeper.connect': 'c251-132:2181',\n",
       "  'zookeeper.connection.timeout.ms': '6000'},\n",
       " 'master_url': 'c251-132:2181'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_pilot.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_pilot.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_compute_description = {\n",
    "    \"resource\":\"slurm://localhost\",\n",
    "    \"working_directory\": os.path.join('/work/01131/tg804093/wrangler/', \"work\"),\n",
    "    \"number_cores\": 48,\n",
    "    \"cores_per_node\":1,\n",
    "    \"project\": \"TG-MCB090174\",\n",
    "    \"queue\": \"normal\",\n",
    "    \"walltime\": 59,\n",
    "    \"type\":\"dask\"\n",
    "}\n",
    "dask_pilot = pilot.streaming.PilotComputeService.create_pilot(pilot_compute_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
