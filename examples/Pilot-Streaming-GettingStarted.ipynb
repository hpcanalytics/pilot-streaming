{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Pilot-Streaming\n",
    "\n",
    "In the first step we need to import all required packages and modules into the Python Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T17:59:21.386383Z",
     "start_time": "2017-12-28T17:59:21.364643Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pilot.streaming' from '/home/01131/tg804093/anaconda2/lib/python2.7/site-packages/pilot/streaming.pyc'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "import pilot.streaming\n",
    "sys.modules['pilot.streaming']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pilot-Compute Description is a simple key/value style description of the cluster environment that should be started. Alternatively, the commandline tool delivered with this package can be used:\n",
    "\n",
    "     psm --resource=slurm://localhost --queue=normal --walltime=59 --number_cores=48 --framework kafka "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:00:04.950564Z",
     "start_time": "2017-12-28T17:59:22.095228Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Run python Args: ['-m', 'spark.bootstrap_spark']\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Job: 59155 State : Pending\n",
      "/home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "DEBUG:root:Looking for /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-e41381a6-ec5a-11e7-a7ed-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"SAGA_VERBOSE\"]=\"100\"\n",
    "pilot_compute_description = {\n",
    "    \"resource\":\"slurm://localhost\",\n",
    "    \"working_directory\": os.path.join(os.getcwd(), \"work\"),\n",
    "    \"number_cores\": 48,\n",
    "    \"cores_per_node\":1,\n",
    "    \"project\": \"TG-MCB090174\",\n",
    "    \"queue\": \"normal\",\n",
    "    \"walltime\": 59,\n",
    "    \"type\":\"spark\"\n",
    "}\n",
    "p = pilot.streaming.PilotComputeService.create_pilot(pilot_compute_description)\n",
    "\n",
    "#print str(p.get_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print str(p.get_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T17:51:55.430862Z",
     "start_time": "2017-12-28T17:51:55.093479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-a6a53c88-ec5a-11e7-83e0-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "Open master file: /home/01131/tg804093/notebooks/pilot-streaming/examples/work/spark-a6a53c88-ec5a-11e7-83e0-549f35083c1c/spark-2.2.1-bin-hadoop2.7/conf/masters\n",
      "Create Spark Context for URL: spark://129.114.58.133:7077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:py4j.java_gateway:GatewayClient.port is deprecated and will be removed in version 1.0. Use GatewayParameters instead.\n",
      "DEBUG:py4j.java_gateway:JavaGateway.auto_convert is deprecated and will be removed in version 1.0. Use GatewayParameters instead.\n",
      "DEBUG:py4j.java_gateway:JavaGateway.gateway_client is deprecated and will be removed in version 1.0. Use GatewayParameters instead.\n",
      "DEBUG:py4j.java_gateway:Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.SparkConf\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yv\n",
      "DEBUG:py4j.java_gateway:Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.api.java.*\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yv\n",
      "DEBUG:py4j.java_gateway:Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.api.python.*\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yv\n",
      "DEBUG:py4j.java_gateway:Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.ml.python.*\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yv\n",
      "DEBUG:py4j.java_gateway:Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.mllib.api.python.*\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yv\n",
      "DEBUG:py4j.java_gateway:Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.sql.*\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yv\n",
      "DEBUG:py4j.java_gateway:Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.sql.hive.*\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yv\n",
      "DEBUG:py4j.java_gateway:Command to send: j\n",
      "i\n",
      "rj\n",
      "scala.Tuple2\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yv\n",
      "DEBUG:py4j.java_gateway:Command to send: r\n",
      "u\n",
      "SparkConf\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ycorg.apache.spark.SparkConf\n",
      "DEBUG:py4j.java_gateway:Command to send: i\n",
      "org.apache.spark.SparkConf\n",
      "bTrue\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yro0\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "set\n",
      "sspark.master\n",
      "sspark://129.114.58.133:7077\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yro1\n",
      "DEBUG:py4j.java_gateway:Command to send: m\n",
      "d\n",
      "o1\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yv\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "set\n",
      "sspark.app.name\n",
      "sspark-a6a53c88-ec5a-11e7-83e0-549f35083c1c\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yro2\n",
      "DEBUG:py4j.java_gateway:Command to send: m\n",
      "d\n",
      "o2\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yv\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.serializer.objectStreamReset\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ybfalse\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "set\n",
      "sspark.serializer.objectStreamReset\n",
      "s100\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yro3\n",
      "DEBUG:py4j.java_gateway:Command to send: m\n",
      "d\n",
      "o3\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yv\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.rdd.compress\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ybfalse\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "set\n",
      "sspark.rdd.compress\n",
      "sTrue\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yro4\n",
      "DEBUG:py4j.java_gateway:Command to send: m\n",
      "d\n",
      "o4\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yv\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.master\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ybtrue\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.app.name\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ybtrue\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.master\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ybtrue\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "get\n",
      "sspark.master\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ysspark://129.114.58.133:7077\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.app.name\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ybtrue\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "get\n",
      "sspark.app.name\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ysspark-a6a53c88-ec5a-11e7-83e0-549f35083c1c\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.home\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ybfalse\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o0\n",
      "getAll\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yto5\n",
      "DEBUG:py4j.java_gateway:Command to send: a\n",
      "e\n",
      "o5\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yi5\n",
      "DEBUG:py4j.java_gateway:Command to send: a\n",
      "g\n",
      "o5\n",
      "i0\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yro6\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o6\n",
      "_1\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ysspark.rdd.compress\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o6\n",
      "_2\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ysTrue\n",
      "DEBUG:py4j.java_gateway:Command to send: a\n",
      "e\n",
      "o5\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yi5\n",
      "DEBUG:py4j.java_gateway:Command to send: a\n",
      "g\n",
      "o5\n",
      "i1\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yro7\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o7\n",
      "_1\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ysspark.master\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o7\n",
      "_2\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ysspark://129.114.58.133:7077\n",
      "DEBUG:py4j.java_gateway:Command to send: a\n",
      "e\n",
      "o5\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yi5\n",
      "DEBUG:py4j.java_gateway:Command to send: a\n",
      "g\n",
      "o5\n",
      "i2\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yro8\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o8\n",
      "_1\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ysspark.serializer.objectStreamReset\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o8\n",
      "_2\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ys100\n",
      "DEBUG:py4j.java_gateway:Command to send: a\n",
      "e\n",
      "o5\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yi5\n",
      "DEBUG:py4j.java_gateway:Command to send: a\n",
      "g\n",
      "o5\n",
      "i3\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !yro9\n",
      "DEBUG:py4j.java_gateway:Command to send: c\n",
      "o9\n",
      "_1\n",
      "e\n",
      "\n",
      "DEBUG:py4j.java_gateway:Answer received: !ysspark.app.name\n"
     ]
    }
   ],
   "source": [
    "sc = p.get_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3])\n",
    "rdd.map(lambda a: a*a).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
